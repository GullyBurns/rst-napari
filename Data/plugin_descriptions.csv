,name,summary,description
0,PartSeg,"PartSeg is python GUI for bio imaging analysis especially nucleus analysis,","PartSeg












PartSeg is a GUI and a library for segmentation algorithms.
This application is designed to help biologist with segmentation based on threshold and connected components.

Tutorials

Tutorial: Chromosome 1 (as gui) link
Data for chromosome 1 tutorial link
Tutorial: Different neuron types (as library) link

Installing


From binaries:

Windows (build on Windows 10)
Linux (build on Ubuntu 18.04)
MacOS (build on MacOS Mojave)



With pip:

From pypi: pip install PartSeg[pyqt]
From repository: pip install git+https://github.com/4DNucleome/PartSeg.git



Running
If you downloaded binaries, run the PartSeg (or PartSeg.exe for Windows) file inside the PartSeg folder
If you installed from repository or from pip, you can run it with PartSeg command or python -m PartSeg.
First option does not work on Windows.
PartSeg export few commandline options:

--no_report - disable error reporting
--no_dialog - disable error reporting and error dialog. Use only when running from terminal.
segmentation_analysis - skip launcher and start analysis gui
segmentation - skip launcher and start segmentation gui

napari plugin
PartSeg provides napari plugins for io to allow reading projects format in napari viewer.
Save Format
Saved projects are tar files compressed with gzip or bz2.
Metadata is saved in data.json file (in json format).
Images/masks are saved as *.npy (numpy array format).
Interface
Launcher. Choose the program that you will launch:

Main window of Segmentation Analysis:

Main window of Segmentation Analysis with view on measurement result:

Window for creating a set of measurements:

Main window of Mask Segmentation:

Laboratory
Laboratory of Functional and Structural Genomics
http://4dnucleome.cent.uw.edu.pl/
Cite as
Bokota, G., Sroka, J., Basu, S. et al. PartSeg: a tool for quantitative feature extraction
from 3D microscopy images for dummies. BMC Bioinformatics 22, 72 (2021).
https://doi.org/10.1186/s12859-021-03984-1
Changelog
0.13.10

change tiff save backend to ome-tiff
add DistanceROIROI and ROINeighbourhoodROI measurements

0.13.9

annotation show bugfix

0.13.8

napari deprecation fixes
speedup simple measurement
bundle plugins initial support

0.13.7

add measurements widget for napari
fix bug in pipeline usage

0.13.6

Hotfix release
Prepare for a new napari version

0.13.5

Small fixes for error reporting
Fix mask segmentation

0.13.4

Bugfix for outdated profile/pipeline preview

0.13.3

Fix saving roi_info in multiple files and history

0.13.2

Fix showing label in select label tab

0.13.1

Add Haralick measurements
Add obsep file support

0.13.0

Add possibility of custom input widgets for algorithms
Switch to napari Colormaps instead of custom one
Add points visualization
Synchronization widget for builtin (View menu) napari viewer
Drop Python 3.6

0.12.7

Fixes for napari 0.4.6

0.12.6

Fix prev_mask_get
Fix cache mechanism on mask change
Update PyInstaller build

0.12.5

Fix bug in pipeline execute

0.12.4

Fix ROI Mask windows related build (signal not properly connected)

0.12.3

Fix ROI Mask

0.12.2

Fix windows bundle

0.12.1

History of last opened files
Add ROI annotation and ROI alternatives
Minor bugfix

0.12.0

Toggle multiple files widget in View menu
Toggle Left panel in ROI Analysis in View Menu
Rename Mask Segmentation to ROI Mask
Add documentation for interface
Add Batch processing tutorial
Add information about errors to batch processing output file
Load image from the batch prepare window
Add search option in part of list and combo boxes
Add drag and drop mechanism to load list of files to batch window.

0.11.5

add side view to viewer
fix horizontal view for Measurements result table

0.11.4

bump to napari 0.3.8 in bundle
fix bug with not presented segmentation loaded from project
add frame (1 pix) to image cat from base one based on segmentation
pin to Qt version to 5.14

0.11.3

prepare for napari 0.3.7
split napari io plugin on multiple part
better reporting for numpy array via sentry
fix setting color for mask marking

0.11.2

Speedup image set in viewer using async calls
Fix bug in long name of sheet with parameters

0.11.1

Add screenshot option in View menu
Add Voxels measurements

0.11.0

Make sprawl algorithm name shorter
Unify capitalisation of measurement names
Add simple measurements to mask segmentation
Use napari as viewer
Add possibility to preview additional output of algorithms (In View menu)
Update names of available Algorithm and Measurement to be more descriptive.

0.10.8

fix synchronisation between viewers in Segmentation Analysis
fix batch crash on error during batch run, add information about file on which calculation fails
add changelog preview in Help > About

0.10.7

in measurements, on empty list of components mean will return 0

0.10.6

fix border rim preview
fix problem with size of image preview
zoom with scroll and moving if rectangle zoom is not marked

0.10.5

make PartSeg PEP517 compatible.
fix multiple files widget on Windows (path normalisation)

0.10.4

fix slow zoom

0.10.3

deterministic order of elements in batch processing.

0.10.2

bugfixes

0.10.1

bugfixes

0.10.0

Add creating custom label coloring.
Change execs interpreter to python 3.7.
Add masking operation in Segmentation Mask.
Change license to BSD.
Allow select root type in batch processing.
Add median filter in preview.

0.9.7

fix bug in compare mask

0.9.6

fix bug in loading project with mask
upgrade PyInstaller version (bug  GHSA-7fcj-pq9j-wh2r)

0.9.5

fix bug in loading project in ""Segmentation analysis""

0.9.4

read mask segmentation projects
choose source type in batch
add initial support to OIF and CZI file format
extract utils to PartSegCore module
add automated tests of example notebook
reversed mask
load segmentation parameters in mask segmentation
allow use sprawl in segmentation tool
add radial split of mask for measurement
add all measurement results in batch, per component sheet

0.9.3

start automated build documentation
change color map backend and allow for user to create custom color map.
segmentation compare
update test engines
support of PySide2

0.9.2.3

refactor code to make easier create plugin for mask segmentation
create class base updater for update outdated algorithm description
fix save functions
fix different bugs

0.9.2.2

extract static data to separated package
update marker of fix range and add mark of gauss in channel control

0.9.2.1

add VoteSmooth and add choosing of smooth algorithm

0.9.2


add pypi base check for update


remove resetting image state when change state in same image


in stack segmentation add options to picking components from segmentation's


in mask segmentation add:

preview of segmentation parameters per component,
save segmentation parameters in save file
new implementation of batch mode.



0.9.1


Add multiple files widget


Add Calculating distances between segmented object and mask


Batch processing plan fixes:

Fix adding pipelines to plan
Redesign mask widget



modify measurement backend to allow calculate multi channel measurements.


0.9
Begin of changelog"
1,PlatyMatch,PlatyMatch allows registration of volumetric images of embryos by establishing correspondences between cells,"








Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence
Table of Contents

Introduction
Dependencies
Getting Started
Datasets
Registering your data
Contributing
Issues
Citation

Introduction
This repository hosts the version of the code used for the publication Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence. 
We refer to the techniques elaborated in the publication, here as PlatyMatch. PlatyMatch performs a linear registration of volumetric, microscopy images of embryos by establishing correspondences between cells. 
PlatyMatch first detects nuclei in the two images being considered, next calculates unique shape context features for each nucleus detection which encapsulates the neighborhood as seen by that nucleus, and finally identifies pairs of matching nuclei through maximum bipartite matching applied to the pairwise distance matrix generated from these features. 
Dependencies
You can install PlatyMatch via pip:
conda create -y -n PlatyMatchEnv python==3.8
conda activate PlatyMatchEnv
python3 -m pip install PlatyMatch
Getting Started
Type in the following commands in a new terminal window.
conda activate PlatyMatchEnv
napari
Next, select PlatyMatch from Plugins> Add Dock Widget.
Datasets
Datasets are available in bic_eccv_data.zip as release assets here.
These comprise of images, nuclei detections and keypoint locations for confocal images of 12 individual specimens under the 01-insitus directory and static snapshots of a live embryo imaged through Light Sheet Microscopy under the 02-live directory. 
Folders with the same name in these two directories correspond in their developmental age, for example, 01-insitus/02 corresponds to 02-live/02, 01-insitus/03 corresponds to 02-live/03 and so on.   
Registering your data

Detect Nuclei 
Drag and drop your images in the viewer 
Click on Sync with Viewer button to refresh the drop-down menus 
Select the appropriate image in the drop down menu (for which nuclei detections are desired)
Select Detect Nuclei from the drop-down menu
Specify the anisotropy factor (Anisotropy (Z)) (i.e. the ratio of the size of the z pixel with respect to the x or y pixel. This factor is typically more than 1.0 because the z dimension is often undersampled)
Ideally min scales and max scales should be estimated from your data (min_scale should be set as min_radius/sqrt(3) and max_scale should be set as max_radius/sqrt(3). The default values of min_scale=5 and max_scale=9 generally works well).  
Click Run Scale Space Log button. Please note that this step takes a few minutes.
Wait until a confirmation message suggesting that nuclei detection is over shows up on the terminal
Export the nuclei locations (Export detections to csv) to a csv file
Repeat this step for all images which need to be matched



https://user-images.githubusercontent.com/34229641/120660618-cd5d3980-c487-11eb-8996-326264a4df87.mp4

Estimate Transform
In case, nuclei were exported to a csv in the Detect Nuclei panel, tick csv checkbox
If the nuclei detected were specified in the order id, z, y and x in the csv file, then tick IZYXR checkbox
Additionally if there is a header in the csv file, tick Header checkbox
Load the detections for the Moving Image, which is defined as the image which will be transformed to later match another fixed image
Load the detections for the Fixed Image
Click on Run pushbutton. Once the calculation is complete, a confirmation message shows up in the terminal. Export the transform matrix to a csv (Note that this step can take a few minutes)
It is also possible to estimate the transform in a supervised fashion. For this, upload the locations of a few matching keypoints in both images. These locations serve to provide a good starting point for the transform calculation. Once the keypoint files have been uploaded for both the images, then click Run and then export the transform matrix to a csv file 



https://user-images.githubusercontent.com/34229641/120685628-53857a00-c4a0-11eb-8f92-7ffac730e28a.mp4

Evaluate Metrics
Drag images which need to be transformed, in the viewer
Click on Sync with Viewer button to refresh the drop-down menus
Specify the anisotropy factor (Moving Image Anisotropy (Z) and Fixed Image Anisotropy (Z)) (i.e. the ratio of the size of the z pixel with respect to the x or y pixel. This factor is typically more than 1.0 because the z dimension is often undersampled)
Load the transform which was calculated in the previous steps
If you simply wish to export a transformed version of the moving image, click on Export Transformed Image
Additionally, one could quantify metrics such as average registration error evaluated on a few keypoints. To do so, tick the csv checkbox, if keypoints and detections are available as a csv file. Then load the keypoints for the moving image (Moving Kepoints) and the fixed image (Fixed Keypoints)
Also, upload the detections calculated in the previous steps (Detect Nuclei)  by uploading the Moving Detections and the Fixed Detections
Click on the Run push button
The text fields such as Matching Accuracy(0 to 1, with 1 being the best) and Average Registration Error (the lower the better) should become populated once the results are available



https://user-images.githubusercontent.com/34229641/120685654-5b451e80-c4a0-11eb-8d7d-de58b8b8304d.mp4
Contributing
Contributions are very welcome. Tests can be run with tox.
Issues
If you encounter any problems, please file an issue along with a detailed description.
Citation
If you find our work useful in your research, please consider citing:
bibtex
@InProceedings{10.1007/978-3-030-66415-2_30,
author=""Lalit, Manan and Handberg-Thorsager, Mette and Hsieh, Yu-Wen and Jug, Florian and Tomancak, Pavel"",
editor=""Bartoli, Adrien
and Fusiello, Andrea"",
title=""Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence"",
booktitle=""Computer Vision -- ECCV 2020 Workshops"",
year=""2020"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""458--473"",
isbn=""978-3-030-66415-2""
}
PlatyMatch plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template."
2,affinder,Quickly find the affine matrix mapping one image to another using manual correspondence points annotation,"Description
This GUI plugin allows you to quickly find the affine matrix mapping
one image to another using manual correspondence points annotation.
More simply, this plugin allows you to select corresponding points
on an image, and a second image you wish to transform. It computes 
the requisite transformation matrix using Affine Transform, Euclidean Transform, 
or Similarity Transform, and performs this transformation on the
moving image, aligning it to the reference image.
https://user-images.githubusercontent.com/17995243/120086403-f1d0b300-c121-11eb-8000-a44a2ac54339.mp4
Who is This For?
This is a simple plugin which can be used on any 2D images, provided
they can be loaded as layers into napari. The images need not be the same
file format and this plugin also works with labels layers.
No prior understanding of the transformation methods is required, as
they perform in the background based on the reference points selected.
How to Guide
You will need a combination of two or more 2D image and/or labels layers 
loaded into napari. Once you have installed affinder, you can find it in
the dock widgets menu.

The first two dropdown boxes will be populated with the layers currently
loaded into napari. Select a layer to use as reference, and another to
transform.

Next, you can select the transformation model to use (affine is selected by default
and is the least rigid transformation of those available). See below for a
description of the different models.
Finally, you can optionally select a path to a text file for saving out the
resulting transformation matrix.
When you click Start, affinder will add two points layers to napari. 
The plugin will also bring your reference image in focus, and its associated points
layer. You can then start adding reference points by clicking on your image.

Once three points are added, affinder will switch focus to the moving image,
and you should then proceed to select the corresponding three points.

affinder will immediately transform the moving image to align the points you've
selected when you add your third corresponding point to your moving image.

From there, you can continue iteratively adding points until you 
are happy with the alignment. Affinder will switch focus between
reference and moving image with each point.
Click Finish to exit affinder.
Transformation Models
There are three transformation models available for use with affinder.
They are listed here in order of increasing rigidity in the types of
transforms they will allow. The eponymous Affine Transform is the 
least rigid and is the default choice.


Affine Transform: 
the least rigid transformation, it preserves
lines and parallelism, but not necessarily distance and angles. Translation,
scaling, similarity, reflection, rotation and shearing are all valid
affine transformations.


Similarity Transform: 
this is a ""shape preserving"" transformation, producing objects which are 
geometrically similar. Translation, rotation, reflection and uniform scaling are 
valid similarity transforms. Shearing is not.


Euclidean Transform:
Also known as a rigid transformation, this transform preserves the Euclidean
distance between each pair of points on the image. This includes rotation,
translation and reflection but not scaling or shearing.


Getting Help
If you find a bug with affinder, or would like support with using it, please raise an
issue on the GitHub repository.
How to Cite
Many plugins may be used in the course of published (or publishable) research, as well as
during conference talks and other public facing events. If you'd like to be cited in
a particular format, or have a DOI you'd like used, you should provide that information here."
3,bfio,Simple reading and writing classes for tiled tiffs using Bioformats.,"BioFormats Input/Output utility (bfio v2.1.9)




This tool is a simplified but powerful interface to 
Bioformats
using jpype for direct access to the library. This tool is designed with
scalable image analysis in mind, with a simple interface to treat any image
like a memory mapped array.
Docker containers with all necessary components are available (see
Docker Containers section).
Summary

Installation
Docker
Documentation
Contributing
Versioning
Authors
License
Acknowledgments

Installation
Setting up Java
Note: bfio can be used without Java, but only the python and zarr
backends will be useable. Only files in tiled OME Tiff or OME Zarr format can be
read/written.
In order to use the Java backend, it is necessary to first install the JDK.
The bfio package is generally tested with
JDK 8,
but JDK 11 and later also appear to work.
Installing bfio
The bfio package and the core dependencies (numpy, tifffile, imagecodecs) can
be installed using pip:
pip install bfio
Additionally, bfio with other dependencies can be installed:

pip install bfio[jpype] - Adds support for BioFormats/Java
pip install bfio[zarr] - Adds support for OME Zarr
pip install bfio[all] - Installs all dependencies.

Docker
labshare/polus-bfio-util:2.1.8
Ubuntu based container with bfio and all dependencies (including Java).
labshare/polus-bfio-util:2.1.8-imagej
Same as above, except comes with ImageJ and PyImageJ.
labshare/polus-bfio-util:2.1.8-tensorflow
Tensorflow container with bfio isntalled.
Documentation
Documentation and examples are available on
Read the Docs.
Versioning
We use SemVer for versioning. For the versions
available, see the tags on this
repository.
Authors
Nick Schaub (nick.schaub@nih.gov, nick.schaub@labshare.org)
License
This project is licensed under the MIT License
Creative Commons License - see the LICENSE file for
details
Acknowledgments

Parts of this code were written/modified from existing code found in
    tifffile.
"
4,brainglobe-napari-io,Read and write files from the BrainGlobe neuroanatomy suite,"napari-cellfinder





Visualise cellfinder and brainreg results with napari

Installation
This package is likely already installed 
(e.g. with cellfinder, brainreg or another napari plugin), but if you want to 
install it again, either use the napari plugin install GUI or you can 
install brainglobe-napari-io via pip:
pip install brainglobe-napari-io

Usage

Open napari (however you normally do it, but typically just type napari into your terminal, or click on your desktop icon)

brainreg
Sample space
Drag your brainreg output directory (the one with the log file) onto the napari window.
Various images should then open, including:
* Registered image - the image used for registration, downsampled to atlas resolution
* atlas_name - e.g. allen_mouse_25um the atlas labels, warped to your sample brain
* Boundaries - the boundaries of the atlas regions
If you downsampled additional channels, these will also be loaded.
Most of these images will not be visible by default. Click the little eye icon to toggle visibility.
N.B. If you use a high resolution atlas (such as allen_mouse_10um), then the files can take a little while to load.

Atlas space
napari-brainreg also comes with an additional plugin, for visualising your data 
in atlas space. 
This is typically only used in other software, but you can enable it yourself:
* Open napari
* Navigate to Plugins -> Plugin Call Order
* In the Plugin Sorter window, select napari_get_reader from the select hook... dropdown box
* Drag brainreg_read_dir_standard_space (the atlas space viewer plugin) above brainreg_read_dir (the normal plugin) to ensure that the atlas space plugin is used preferentially.
cellfinder
Load cellfinder XML file

Load your raw data (drag and drop the data directories into napari, one at a time)
Drag and drop your cellfinder XML file (e.g. cell_classification.xml) into napari.

Load cellfinder directory

Load your raw data (drag and drop the data directories into napari, one at a time)
Drag and drop your cellfinder output directory into napari.

The plugin will then load your detected cells (in yellow) and the rejected cell 
candidates (in blue). If you carried out registration, then these results will be 
overlaid (similarly to the loading brainreg data, but transformed to the 
coordinate space of your raw data).

Loading raw data

Loading cellfinder results
Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the MIT license,
""brainglobe-napari-io"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
5,brainreg-napari,Multi-atlas whole-brain microscopy registration,"




brainreg-napari
Napari plugin to run brainreg, 
developed by Stephen Lenzi.
Installation
bash
pip install brainreg-napari
Usage
Documentation for the plugin is to come, but documentation for the original 
brainreg can be found here 
and a tutorial is here. 
For segmentation of bulk structures in 3D space 
(e.g. injection sites, Neuropixels probes), please see 
brainreg-segment.
This software is at a very early stage, and was written with our data in mind. 
Over time we hope to support other data types/formats. If you have any issues, please get in touch on the forum or by 
raising an issue. 
If you have any other questions, 
please send an email.
Details
brainreg is an update to 
amap (itself a port 
of the original Java software) 
to include multiple registration backends, and to support the many atlases 
provided by bg-atlasapi.
The aim of brainreg is to register the template brain
 (e.g. from the Allen Reference Atlas)
  to the sample image. Once this is complete, any other image in the template
  space can be aligned with the sample (such as region annotations, for 
  segmentation of the sample image). The template to sample transformation
  can also be inverted, allowing sample images to be aligned in a common 
  coordinate space.
To do this, the template and sample images are filtered, and then registered in 
a three step process (reorientation, affine registration, and freeform 
registration.) The resulting transform from template to standard space is then
applied to the atlas. 
Full details of the process are in the 
original aMAP paper.

Overview of the registration process
Citing brainreg
If you find brainreg useful, and use it in your research, please let us know and also cite the preprint:

Tyson, A. L., Vélez-Fort, M.,  Rousseau, C. V., Cossell, L., Tsitoura, C., Obenhaus, H. A., Claudi, F., Lenzi, S. C., Branco, T.,  Margrie, T. W. (2021) “Tools for accurate post hoc determination of marker location within whole-brain microscopy images’ bioRxiv, doi.org/10.1101/2021.05.21.445133

Please also cite aMAP (the original pipeline from which this software is based):

Niedworok, C.J., Brown, A.P.Y., Jorge Cardoso, M., Osten, P., Ourselin, S., Modat, M. and Margrie, T.W., (2016). AMAP is a validated pipeline for registration and segmentation of high-resolution mouse brain data. Nature Communications. 7, 1–9. https://doi.org/10.1038/ncomms11879

Lastly, if you can, please cite the BrainGlobe Atlas API that provided the atlas:

Claudi, F., Petrucco, L., Tyson, A. L., Branco, T., Margrie, T. W. and Portugues, R. (2020). BrainGlobe Atlas API: a common interface for neuroanatomical atlases. Journal of Open Source Software, 5(54), 2668, https://doi.org/10.21105/joss.02668

Don't forget to cite the developers of the atlas that you used (e.g. the Allen Brain Atlas)!"
6,brainreg-segment,Manual segmentation of 3D brain structures in a common anatomical space,"







brainreg-segment
Segmentation of 1/2/3D brain structures in a common anatomical space
brainreg-segment is a companion to brainreg allowing manual segmentation of regions/objects within the brain (e.g. injection sites, probes etc.) allowing for automated analysis of brain region distribution, and visualisation (e.g. in brainrender).
Installation
brainreg-segment comes bundled with brainreg, so see the brainreg installation instructions. 
brainreg-segment can be installed on it's own (pip install brainreg-segment), but you will need to register your data with brainreg first. 
Usage
See user guide.
If you have any questions, head over to the image.sc forum.
Citing brainreg-segment
If you find brainreg-segment useful, and use it in your research, please let us know and also cite the preprint:

Tyson, A. L., Vélez-Fort, M.,  Rousseau, C. V., Cossell, L., Tsitoura, C., Obenhaus, H. A., Claudi, F., Lenzi, S. C., Branco, T.,  Margrie, T. W. (2021) “Tools for accurate post hoc determination of marker location within whole-brain microscopy images’ bioRxiv, doi.org/10.1101/2021.05.21.445133
"
7,cellfinder-napari,Efficient cell detection in large images,"cellfinder-napari












Efficient cell detection in large images (e.g. whole mouse brain images)
This package implements the cell detection algorithm from 
Tyson, Rousseau & Niedworok et al. (2021) 
for napari, based on the 
cellfinder-core package.
This algorithm can also be used within the original 
cellfinder software for 
whole-brain microscopy analysis.


Visualising detected cells in the cellfinder napari plugin

Instructions
Installation
Once you have installed napari. 
You can install napari either through the napari plugin installation tool, or 
directly from PyPI with:
bash
pip install cellfinder-napari
Usage
Full documentation can be 
found here. 
This software is at a very early stage, and was written with our data in mind. 
Over time we hope to support other data types/formats. If you have any 
questions or issues, please get in touch by 
email, 
on the forum or by 
raising an issue.

Illustration
Introduction
cellfinder takes a stitched, but otherwise raw dataset with at least 
two channels:
 * Background channel (i.e. autofluorescence)
 * Signal channel, the one with the cells to be detected:

Raw coronal serial two-photon mouse brain image showing labelled cells
Cell candidate detection
Classical image analysis (e.g. filters, thresholding) is used to find 
cell-like objects (with false positives):

Candidate cells (including many artefacts)
Cell candidate classification
A deep-learning network (ResNet) is used to classify cell candidates as true 
cells or artefacts:

Cassified cell candidates. Yellow - cells, Blue - artefacts
Citing cellfinder
If you find this plugin useful, and use it in your research, please cite the preprint outlining the cell detection algorithm:

Tyson, A. L., Rousseau, C. V., Niedworok, C. J., Keshavarzi, S., Tsitoura, C., Cossell, L., Strom, M. and Margrie, T. W. (2021) “A deep learning algorithm for 3D cell detection in whole mouse brain image datasets’ PLOS Computational Biology, 17(5), e1009074
https://doi.org/10.1371/journal.pcbi.1009074

If you use this, or any other tools in the brainglobe suite, please
 let us know, and 
 we'd be happy to promote your paper/talk etc."
8,cellpose-napari,a generalist algorithm for anatomical segmentation,"cellpose-napari 











a napari plugin for anatomical segmentation of general cellular images

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
The plugin code was written by Carsen Stringer, and the cellpose code was written by Carsen Stringer and Marius Pachitariu. To learn about Cellpose, read the paper or watch this talk. 
For support with the plugin, please open an issue. For support with cellpose, please open an issue on the cellpose repo. 
If you use this plugin please cite the paper:
::
  @article{stringer2021cellpose,
  title={Cellpose: a generalist algorithm for cellular segmentation},
  author={Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
  journal={Nature Methods},
  volume={18},
  number={1},
  pages={100--106},
  year={2021},
  publisher={Nature Publishing Group}
  }


Installation
Install an Anaconda distribution of Python -- Choose Python 3 and your operating system. Note you might need to use an anaconda prompt if you did not add anaconda to the path. 
You can install cellpose-napari via [pip]:
pip install cellpose-napari

If install fails in your base environment, create a new environment:
1. Download the environment.yml file from the repository. You can do this by cloning the repository, or copy-pasting the text from the file into a text document on your local computer.
2. Open an anaconda prompt / command prompt with conda for python 3 in the path
3. Change directories to where the environment.yml is and run conda env create -f environment.yml
4. To activate this new environment, run conda activate cellpose-napari
5. You should see (cellpose-napari) on the left side of the terminal line. 
If you have issues with cellpose installation, see the cellpose docs for more details, and then if the suggestions fail, open an issue.
Upgrading software
You can upgrade the plugin with
~~~
pip install cellpose-napari --upgrade
~~~
and you can upgrade cellpose with
~~~
pip install cellpose --upgrade
~~~
GPU version (CUDA) on Windows or Linux
If you plan on running many images, you may want to install a GPU version of torch (if it isn't already installed).
Before installing the GPU version, remove the CPU version:
~~~
pip uninstall torch
~~~
Follow the instructions here to determine what version to install. The Anaconda install is recommended along with CUDA version 10.2. For instance this command will install the 10.2 version on Linux and Windows (note the torchvision and torchaudio commands are removed because cellpose doesn't require them):
~~~
conda install pytorch cudatoolkit=10.2 -c pytorch
~~~~
When upgrading GPU Cellpose in the future, you will want to ignore dependencies (to ensure that the pip version of torch does not install):
~~~
pip install --no-deps cellpose --upgrade
~~~
Installation of github version
Follow steps from above to install the dependencies. In the github repository, run pip install -e . and the github version will be installed. If you want to go back to the pip version of cellpose-napari, then say pip install cellpose-napari.
Running the software
Open napari with the cellpose-napari dock widget open
napari -w cellpose-napari
There is sample data in the File menu, or get started with your own images!
Detailed usage documentation.
Contributing
Contributions are very welcome. Tests are run with pytest.
License
Distributed under the terms of the BSD-3 license,
""cellpose-napari"" is free and open source software.
Dependencies
cellpose-napari relies on the following excellent packages (which are automatically installed with conda/pip if missing):
- napari
- magicgui
cellpose relies on the following excellent packages (which are automatically installed with conda/pip if missing):
- torch
- numpy (>=1.16.0)
- numba
- scipy
- natsort
- tifffile
- opencv"
9,devbio-napari,A collection of napari plugins useful for studying developmental biology,"devbio-napari



A collection of napari plugins useful for studying developmental biology.

File input/output plugins
aicsimageio
napari-itk-io 
ome-zarr
Image exploration and visualization tools
animation
Image segmentation plugins
Cellpose
StarDist
oclrfc
pyclesperanto-assistant
Manual split & merge labels
Image registration
PlatyMatch
Quantitative measurements
scikit-image regionprops
plot-profile
Utilities
brightness-contrast
plugin-search


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
You can install devbio-napari via pip:
conda install -c conda-forge pyopencl jupyter notebook
pip install devbio-napari

Windows users should install pyopencl via conda in advance:
conda install -c conda-forge pyopencl

See also.
Contributing
Contributions are very welcome. If you want to suggest a new napari plugin to become part of this distribution, please make sure it interoperates nicely with the other plugins. For example, if the plugin you suggest provided cell segmentation algorithms, please check if the resulting segmented cells can be analysed using napari-skimage-regionprops.
License
Distributed under the terms of the BSD-3 license,
""devbio-napari"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
10,elastix-napari,A toolbox for rigid and nonrigid registration of images.,"Description
This plugin makes the elastix toolbox for rigid and nonrigid registration of images available in napari.
elastix is open source software, based on the well-known Insight Segmentation and Registration Toolkit (ITK). The software consists of a collection of algorithms that are commonly used to solve (medical) image registration problems. The modular design of elastix allows the user to quickly configure, test, and compare different registration methods for a specific application.
Who is This For?
With this plugin both 2D and 3D images in all file formats available in ITK can be registered.
The plugin supports various transformations including rigid, affine and bspline.
Registration within the plugin is done based on user defined parameters, but for novice users
defaults for each transformation model are available.
How to Guide
Load the images you want to register into napari and select them in the fixed (or reference) and moving image dropdowns of plugin interface.
For fast and easy registration only the preferred transformation (rigid, affine or bspline) has to be selected (see Transformations section for explanation).
For more advanced registrations the following adjustments can be made in the plugin:

Masks for both the fixed and the moving images can be selected to let elastix only include certain areas in the registration. These masks have to be loaded into napari and selected in the correct mask dropdown menus, which appear when the masks box is ticked.
Point sets for both the fixed and the moving images can de selected to use certain points to aid registration. These point set files have to be .txt files in the following format:

index/point\
  #points\
  point1 x point1 y [point1 z]\
  point2 x point2 y [point2 z]
The first line indicates whether the points are given as “indices” (of the fixed image), or as “points” (in
  physical coordinates). The second line stores the number of points that will be specified. After that the
  point data is given. For example:
point\
  3\
  2.32 5.34 -4.12\
  -1.56 0.12 9.23\
  1.00 7.34 -0.23


An initial transform file that specifies a transform that is applied before the registration is done, can be uploaded as a .txt file. For the latest file and transform formats that are supported, see the elastix manual


For the most common registration parameters adjustments can be made in the plugin GUI


Other, less common registration parameters can be adjusted by uploading custom transform parameter file(s). (Select 'custom' in the preset dropdown).



Transformations
In the plugin 3 common transformations are available as presets, other transformations can be done with the 'custom' option in the preset dropdown. The plugin then has the ability to upload custom parameter files in which other transformations can be specified.
The three common transformations are:


Rigid Transform:
Also known as a Euclidean transformation, this transform preserves the Euclidean
distance between each pair of points on the image. This includes rotation,
translation and reflection but not scaling or shearing.


Affine Transform:
This transfrom preserves
lines and parallelism, but not necessarily distance and angles. Translation,
scaling, similarity, reflection, rotation and shearing are all valid
affine transformations.


BSpline Transform:
This is a deformable transformation that preserves none of the properties mentioned in the transforms describe above.


Getting Help
If you find a bug in the elastix napari plugin, or would like support with using it, please raise an
issue on the GitHub repository.
For question specifically about the elastix toolbox we have a mailing list.
Contributions
Contributions to the elastix_napari plugin, itkelastix (the python wrapper) or elastix (the C++ core) on which the plugin is build, are welcome."
11,misic-napari-plugin,segmentation of bacteria,"misic-napari-plugin





segmentation of bacteria

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

Installation
You can install misic-napari-plugin via [pip]:
pip install misic-napari-plugin

License
Distributed under the terms of the [MIT] license,
""misic-napari-plugin"" is free and open source software"
12,napari-accelerated-pixel-and-object-classification,Pixel and label classification using OpenCL-based Random Forest Classifiers,"napari-accelerated-pixel-and-object-classification (APOC)





clEsperanto meets scikit-learn
A yet experimental OpenCL-based Random Forest Classifier for pixel and labeled object classification in napari.

The processed example image maize_clsm.tif
is licensed by David Legland under 
CC-BY 4.0 license
For using the accelerated pixel and object classifiers in python, check out apoc.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
You can install napari-accelerated-pixel-and-object-classification via pip. Note: you also need pyopencl.
conda install pyopencl
pip install napari-accelerated-pixel-and-object-classification

In case of issues in napari, make sure these dependencies are installed properly:
pip install pyclesperanto_prototype
pip install apoc

Usage
[documentation work in progress]
Open an image in napari and add a labels layer. Annotate foreground and background with two different label identifiers. You can also add a third, e.g. a membrane-like region in between to improve segmentation quality.

Click the menu Plugins > Segmentation (Accelerated Pixel and Object Classification) > Train pixel classifier. 
Consider changing the featureset. There are three options for selecting 
small (about 1 pixel sized) objects, 
medium (about 5 pixel sized) object and 
large (about 25 pixel sized) objects.
Make sure the right image and annotation layers are selected and click on Run.

The classifier was saved as temp.cl to disc. You can later re-use it by clicking the menu Plugins > OpenCL Random Forest Classifiers > Predict pixel classifier
Optional: Hide the annotation layer.
Click the menu Plugins > Segmentation (Accelerated Pixel and Object Classification) > Connected Component Labeling.
Make sure the right labels layer is selected. It is supposed to be the result layer from the pixel classification.
Select the object class identifier you used for annotating objects, that's the intensity you drew on objects in the annotation layer.
Hint: If you want to analyse touching neigbors afterwards, activate the fill gaps between labels checkbox.
Click on the Run button.

Optional: Hide the pixel classification result layer. Change the opacity of the connected component labels layer.
Add a new labels layer and annotate different object classes by drawing lines through them. 
In the following example objects with different size and shape were annotated in three classes:
* round, small
* round, large
* elongated

Click the menu Plugins > Segmentation (Accelerated Pixel and Object Classification) > Train object classifier. Select the right layers for training.
The labels layer should be the result from connected components labeling.
The annotation layer should be the just annotated object classes layer.
Select the right features for training. Click on the Run button. 
After training, the classifier will be stored to disc in the file you specified.
You can later re-use it by clicking the menu Plugins > Segmentation (Accelerated Pixel and Object Classification) > Predict label classifier

This is an experimental napari plugin. Feedback is very welcome!
Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-accelerated-pixel-and-object-classification"" is free and open source software
Issues
If you encounter any problems, please open a thread on image.sc along with a detailed description and tag @haesleinhuepf."
13,napari-aicsimageio,AICSImageIO for napari. Multiple file format reading directly into napari using pure Python.,"Features

Supports reading metadata and imaging data for:
CZI
OME-TIFF
TIFF
Any formats supported by aicsimageio
Any additional format supported by imageio



Plugin Variants

There are two variants of this plugin that are added during installation:
* aicsimageio-in-memory, which reads an image fully into memory
* aicsimageio-out-of-memory, which delays reading ZYX chunks until required.
This allows for incredible large files to be read and displayed.
Examples of Features
General Image Reading
All image file formats supported by
aicsimageio will be read and all
raw data will be available in the napari viewer.
In addition, when reading an OME-TIFF, you can view all OME metadata directly in the
napari viewer thanks to ome-types.

Mosaic CZI Reading
When reading CZI images, if the image is a mosaic tiled image, napari-aicsimageio
will return the reconstructed image:

Mosaic LIF Reading
When reading LIF images, if the image is a mosaic tiled image, napari-aicsimageio
will return the reconstructed image:

Citation
If you find aicsimageio (or napari-aicsimageio) useful, please cite as:

AICSImageIO Contributors (2021). AICSImageIO: Image Reading, Metadata Conversion, and Image Writing for Microscopy Images in Pure Python [Computer software]. GitHub. https://github.com/AllenCellModeling/aicsimageio

Free software: BSD-3-Clause"
14,napari-allencell-segmenter,A plugin that enables 3D image segmentation provided by Allen Institute for Cell Science,"napari-allencell-segmenter





A plugin that enables 3D image segmentation provided by Allen Institute for Cell Science
The Allen Cell & Structure Segmenter plugin for napari provides an intuitive graphical user interface to access the powerful segmentation capabilities of an open source 3D segmentation software package developed and maintained by the Allen Institute for Cell Science (classic workflows only with v1.0). ​The Allen Cell & Structure Segmenter is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.
More details about Segmenter can be found at https://allencell.org/segmenter

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
Option 1 (recommended):
After you installed the lastest version of napari, you can go to ""Plugins"" --> ""Install/Uninstall Package(s)"". Then, you will be able to see all available napari plugins and you can find us by name napari-allencell-segmenter. Just click the ""install"" button to install the Segmenter plugin.
Option 2:
You can also install napari-allencell-segmenter via pip:
pip install napari-allencell-segmenter

Quick Start
In the current version, there are two parts in the plugin: workflow editor and batch processing. The workflow editor allows users adjusting parameters in all the existing workflows in the lookup table, so that the workflow can be optimized on users' data. The adjusted workflow can be saved and then applied to a large batch of files using the batch processing part of the plugin. 

Open a file in napari (the plugin is able to support multi-dimensional data in .tiff, .tif. ome.tif, .ome.tiff, .czi)
Start the plugin (open napari, go to ""Plugins"" --> ""napari-allencell-segmenter"" --> ""workflow editor"")
Select the image and channel to work on
Select a workflow based on the example image and target segmentation based on user's data. Ideally, it is recommend to start with the example with very similar morphology as user's data.
Click ""Run All"" to execute the whole workflow on the sample data.
Adjust the parameters of steps, based on the intermediate results. For instruction on the details on each function and the effect of each parameter, click the tooltip button. A complete list of all functions can be found here
Click ""Run All"" again after adjusting the parameters and repeat step 6 and 7 until the result is satisfactory.
Save the workflow
Close the plugin and open the batch processing part by (go to ""Plugins"" --> ""napari-allencell-segmenter"" --> ""batch processing"")
Load the customized workflow (or an off-the-shelf workflow) json file
Load the folder with all the images to process
Click ""Run""

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-allencell-segmenter"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
15,napari-animation,A plugin for making animations in napari,"napari-animation (WIP under active development)





napari-animation is a plugin for making animations in napari.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
It is built off of great work from @guiwitz in naparimovie which was initially submitted to napari in PR#851.

Overview
napari-animation provides a framework for the creation of animations in napari and features:
- an easy to use GUI for interactive creation of animations
- Python tools for programmatic creation of animations
This plugin is currently pre-release and under active development. APIs are likely to change before it's first 0.0.1 release,
but feedback and contributions are welcome.
Installation
You can clone this repository with install locally with
pip install -e .

Examples
Examples can be found in our examples folder. Simple examples for both interactive and headless 
use of the plugin follow.
Interactive
napari-animation can be used interactively by creating an AnimationWidget from a napari Viewer and adding it to
the viewer as a dock widget.
```python
from napari_animation import AnimationWidget
animation_widget = AnimationWidget(viewer)
viewer.window.add_dock_widget(animation_widget, area='right')
```

Headless
napari-animation can also be run headless, allowing for reproducible, scripted creation of animations.
```python
from napari_animation import Animation
animation = Animation(viewer)
viewer.dims.ndisplay = 3
viewer.camera.angles = (0.0, 0.0, 90.0)
animation.capture_keyframe()
viewer.camera.zoom = 2.4
animation.capture_keyframe()
viewer.camera.angles = (-7.0, 15.7, 62.4)
animation.capture_keyframe(steps=60)
viewer.camera.angles = (2.0, -24.4, -36.7)
animation.capture_keyframe(steps=60)
viewer.reset_view()
viewer.camera.angles = (0.0, 0.0, 90.0)
animation.capture_keyframe()
animation.animate('demo.mov', canvas_only=False)
```
Is everything animate-able?
Unfortunately, not yet! Currently differences in the following objects are tracked by the Animation class

Viewer.camera
Viewer.dims
Layer.scale
Layer.translate
Layer.rotate
Layer.shear
layer.opacity
Layer.blending
Layer.visible

Support for more layer attributes will be added in future releases.
Contributing
Contributions are very welcome. Tests and additional infrastructure are being setup.
License
Distributed under the terms of the BSD-3 license,
""napari-animation"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
16,napari-arboretum,Track graph and lineage tree visualization with napari,"




Arboretum
Overview
A dockable widget for Napari for visualizing cell lineage trees.
Features:
+ Lineage tree plot widget
+ Integration with btrack
This project has changed considerably. The Tracks layer, originally developed for this plugin, is now an official layer type in napari. Read the napari documentation here:
 https://napari.org/api/stable/napari.layers.Tracks.html#napari.layers.Tracks
To view the legacy version of this plugin, visit the legacy branch:
https://github.com/quantumjot/arboretum/tree/v1-legacy

Automated cell tracking and lineage tree reconstruction.

Installation
We recommend that you first install napari. Detailed instructions are here: https://github.com/napari/napari.
sh
pip install 'napari[all]'
You can install arboretum directly from napari (using the Plugins > Install/Uninstall Packages(s)... menu) and searching for napari-arboretum.
Alternatively, you can install directly from source:
sh
git clone https://github.com/quantumjot/arboretum.git
cd arboretum
pip install -e .
Usage
Once installed, Arboretum will be visible in the Plugins > Add Dock Widget > napari-arboretum menu in napari.  To visualize a lineage tree, click on one of the tracks in a napari Tracks layer.
You can use btrack to generate tracks from your image data. See the example notebook here:
https://github.com/quantumjot/BayesianTracker/blob/master/examples/segmentation_to_btrack_to_napari.ipynb

TODO:

[ ] Highlight cells in the viewer from the lineage tree view
[ ] Visualize merges
[ ] Color trees by properties

"
17,napari-autolign,A plugin for registering multimodal image volumes based on common segmented structures of interest with point-clouds.,"napari-autolign





A plugin for registering multimodal image volumes based on common segmented structures of interest with point-clouds.

This napari plugin was generated with Cookiecutter using @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-autolign via pip:
pip install napari-autolign

When installing autolign on a Windows machine you may encounter the following error:
error Microsoft Visual C++ 14.0 is required

Ensure that Visual Studios C++ 14.00 is installed
Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the MIT license,
""napari-autolign"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
18,napari-bioformats,"Bioformats for napari, using pims","napari-bioformats






Bioformats plugin for napari using
pims-bioformats

Use this plugin as a fallback!
Anyone coming to napari from the Fiji/ImageJ world will likely be aware of the
incredible Bio-Formats
library.  A heroic effort, built over years, to read
more than a 100 file formats.  Naturally, we want some of that goodness for napari ... hence this plugin.
However: it's important to note that this plugin still
requires having a java runtime engine installed.  This is easy enough to do
(the plugin will ask to install it for you if you're in a conda environment), but
it definitely makes for a more complicated environment setup, it's not very
""pythonic"", and the performance will likely not feel as snappy as a native ""pure""
python module.
So, before you reflexively install this plugin to fill that bio-formats
sized hole in your python heart, consider trying some of the other pure-python
plugins designed to read your format of interest:

Zeiss (.czi): napari-aicsimageio, napari-czifile2
Nikon (.nd2): napari-nikon-nd2, nd2-dask
Leica (.lif): napari-aicsimageio
Olympus (.oif): no plugin?  (but see oiffile )
DeltaVision (.dv, .mrc): napari-dv


if you have a pure-python reader for a bio-formats-supported file format that
you'd like to see added to this list, please open an issue

Installation
The easiest way to install napari-bioformats is via conda, from the
conda-forge channel:
conda install -c conda-forge napari-bioformats

It is also possible to install via pip, but you will need to have a working
JVM installed, and may need to set the JAVA_HOME environment variable
pip install napari-bioformats

First Usage
The first time you attempt to open a file with napari-bioformats, you will
likely notice a long delay as pims downloads the loci_tools.jar (speed will
depend on your internet connection). Subsequent files should open more quickly.
License
Distributed under the terms of the GPLv3 license,
""napari-bioformats"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description.
This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template."
19,napari-brightness-contrast,Advanced layer visualization options,"napari-brightness-contrast





Advanced layer histogram visualization options, e.g. for brightness / contrast

Note: This will not work for big image data at the moment. 
If the user interface feels slow, consider installing pyclesperanto to speed it up.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-brightness-contrast via pip:
pip install napari-brightness-contrast

Contributing
Contributions are very welcome.
License
Distributed under the terms of the BSD-3 license,
""napari-brightness-contrast"" is free and open source software
Issues
If you encounter any problems, please open a thread on image.sc along with a detailed description and tag @haesleinhuepf."
20,napari-brushsettings,A simple plugin to set the brush settings for segmentation in napari,The developer has not yet provided a napari-hub specific description.
21,napari-btrack-reader,A plugin to load btrack files,"napari-btrack-reader





A plugin to load btrack files

This plugin reads tracking data generated by BayesianTracker (btrack).
This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-btrack-reader via pip:
pip install napari-btrack-reader

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-btrack-reader"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
22,napari-ccp4map,Enables napari to read .map files in the ccp4 format. Drag&Drop or press Ctrl+O to read files.,The developer has not yet provided a napari-hub specific description.
23,napari-checkerboard,Compare two images with the itk checkerboard filter,"napari-checkerboard





Compare two images with the itk checkerboard filter


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-checkerboard via pip:
pip install napari-checkerboard

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the Apache Software License 2.0 license,
""napari-checkerboard"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
24,napari-clemreg,A plugin for registering multimodal image volumes based on common segmented structures of interest with point-clouds.,"napari-clemreg





A plugin for registering multimodal image volumes based on common segmented structures of interest with point-clouds.

This napari plugin was generated with Cookiecutter using @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-clemreg via pip:
pip install napari-clemreg

When installing clemreg on a Windows machine you may encounter the following error:
error Microsoft Visual C++ 14.0 is required

Ensure that Visual Studios C++ 14.00 is installed
Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the MIT license,
""napari-clemreg"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
25,napari-compressed-labels-io,Plugin exploring different options for reading and writing compressed and portable labels layers in napari.,"napari-compressed-labels-io





Description
This napari plugin provides readers and writers for labels and their corresponding image layers into zarr format for compression and portability. Each reader/writer pair supports a round trip of saving and loading image and labels layers.
Writers
Two writers are provided by this plugin, each with its own reader.
labels_to_zarr
This writer is an alternative to napari's default label writer and will write an entire labels layer, regardless of its dimensions, into a single zarr file. This writer provides the best compression option and its associated reader get_zarr_labels will read the layer back into napari.
This writer will be called when the user tries to save a selected labels layer into a path ending with .zarr
label_image_pairs_to_zarr
This writer will save 3-dimensional labels and image layers from the viewer into individual zarrs for portability and convenience. For example, given one labels and one image layer of the shape (10, 200, 200) saved to my_stacks.zarr, 10 subdirectories will be created, each with two zarrs inside of shape (200, 200) corresponding to the labels and image layer.
This writer allows users to load stacks of associated images, label them, and then quickly save these stacks out into individual slices for easy loading, viewing and interaction. Its associated reader supports the loading into napari of the whole stack, all layers at one slice of the stack, and an individual layer of a given slice of the stack.
The writer currently supports only 3D layers, with the exception of RGB images of the form (z, y, x, 3), which are also supported.
Readers
Two readers are provided by this plugin for loading the formats saved by each writer. These are detailed below.
get_zarr_labels
This reader will open any zarr file with a .zarray at the top level in path as a labels layer. This is to be used in conjunction with labels_to_zarr.
get_label_image_stack
This reader will open any zarr containing a .zmeta file as layers into napari. Depending on what is being opened, the reader will either load a full stack of labels and images, one slice of a stack of images and labels or an individual layer within a slice. This is to be used in conjunction with label_image_pairs_to_zarr.
.zmeta
This metadata file contains information about the layer types in the stack and in each individual slice, as well as the number of image/label slices. This allows the reader plugin to load the correct layer types with appropriate names both at a stack level and at the individual slice level.
An example .zmeta specification
```json
{
    ""meta"": {
        ""stack"": 7                               # number of slices in the entire stack (1 for an individual slice, 0 for a layer within a slice)
    },
    ""data"": {
        ""image"" : [                              # all image layers must be listed here
            {
                ""name"": ""leaves_example_data"",
                ""shape"": [790, 790, 3],
                ""dtype"": ""uint8"",
                ""rgb"": true                      # where rgb is false the image will be loaded as greyscale (colormap support has not yet been implemented)
            }
        ],
        ""labels"" : [
            {
                ""name"": ""oak"",
                ""shape"": [790, 790],
                ""dtype"": ""int64""
            },
            {
                ""name"": ""bg"",
                ""shape"": [790, 790],
                ""dtype"": ""int64""
            }
        ]
    }
}
```

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-compressed-labels-io via pip:
pip install napari-compressed-labels-io

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the MIT license,
""napari-compressed-labels-io"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
26,napari-console,A plugin that adds a console to napari,"napari-console (WIP, under active development)





A plugin that adds a console to napari

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-console via pip:
pip install napari-console

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-console"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
27,napari-czifile,A napari plugin for reading files via czifile,
28,napari-czifile2,Carl Zeiss Image (.czi) file support for napari,"napari-czifile2















Carl Zeiss Image (.czi) file type support for napari
Open .czi files and interactively view scenes co-registered in the machine's coordinate system using napari
Installation
You can install napari-czifile2 via pip:
pip install napari-czifile2

Authors
Created and maintained by Jonas Windhager jonas.windhager@uzh.ch
Contributing
Contributing
Changelog
Changelog
License
MIT"
29,napari-deepmeta,Segment mouse lungs and metastasis on MRI images.,"napari-deepmeta





Segment mouse lungs and metastasis on MRI images.
This plugin is a demo for the Deepmeta project.


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-deepmeta via pip:
pip install napari-deepmeta


We advise you to create a specific python virtual environment in order to have a clean installation.

Usage
In a terminal, just type napari to open napari.
Open a (x, 128, 128) image, go in the plugin menu, add deepmeta plugin to the dock viewer and click on the button.

By adding the dock widget, a menu will be created on the left of your Napari instance.

In this panel you will find two buttons and one checkbox:

The first button Run lung seg process segmentation and show the result (With the widget segment metas, the button is called Run meta seg).
The second, Reprocess Volume, is useful when you modify contours. It will reprocess all slices to give you a new volume.
The checkbox is here to enhance contrast if your image is dark.

Demo
If you just want to see what we've done, you can try the plugin with the Demo button, this button will load an image and process it
as if you use the plugin in a classic way.
Conf file and custom models
The first time you run the plugin a config file will be created at ~/.config/deepmeta/config.ini.

In this file you can find parameters for postprocessing loop and the path for the models.
Feel free to change values and colors to fit to your needs.

If you want to try another model, you can change the path. Be careful to not having custom objects in you model, otherwise, you'll have to modify the code.

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the MIT license,
""napari-deepmeta"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
30,napari-dexp,A simple plugin to use with napari,"napari-DEXP





A plugin to interface DEXP with napari.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-dexp via pip:
pip install napari-dexp

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-dexp"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
31,napari-dv,Deltavision/MRC file reader for napari,"napari-dv





Deltavision/MRC file reader for napari
Installation
You can install napari-dv via pip:
pip install napari-dv

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the MIT license,
""napari-dv"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
32,napari-dvid,"DVID loader for napari, from a url","napari-dvid





DVID loader for napari, from a url

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-dvid via pip:
pip install napari-dvid

Examples
Once installed, run napari --with napari-dvid to get the plugin sidebar:

Paste in a URL to a DVID volume and hit ""Load"" to load the volume! As an example, try:
https://emdata.janelia.org/api/node/ab6e610d4/grayscale/raw/0_1_2/256_256_256/7500_7000_4400
Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the MIT license,
""napari-dvid"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
33,napari-dzi-zarr,An experimental plugin for viewing Deep Zoom Images (DZI) with napari and zarr.,"napari-dzi-zarr




An experimental plugin for viewing Deep Zoom Images (DZI) with napari + zarr + dask.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Description
The DZI File Format 
is a pyramidal tile source specification where individual tiles are RGB/RGBA JPEG/PNG images. 
DZI is a very popular tile source for zoomable web-viewers like 
OpenSeadragon, and as a result many tile sources are available over 
HTTP. This plugin wraps a DZI tile source (local or remote) as a multiscale Zarr, where each pyramidal level is a zarr.Array of shape (level_height, level_width, 3/4), allowing the same images to be viewed 
in napari + dask.
Installation
You can install napari-dzi-zarr via pip:
pip install napari-dzi-zarr

Usage
This high-resolution scan of Rembrandt's Night Watch is available thanks to R.G Erdmann. More examples can be found on boschproject.org.
$ napari http://hyper-resolution.org/dzi/Rijksmuseum/SK-C-5/SK-C-5_VIS_20-um_2019-12-21.dzi


Contributing
Contributions are very welcome. Tests can be run with tox.
License
Distributed under the terms of the BSD-3 license,
""napari-dzi-zarr"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
34,napari-em-reader,A napari plugin to read .em files,"napari-em-reader





A napari plugin to read .em files

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-em-reader via pip:
pip install napari-em-reader

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-em-reader"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
35,napari-features,"extensible, general-purpose feature extraction",
36,napari-folder-browser,Browse folders of images and open them using double-click,"napari-folder-browser





Browse folders of images and open them using double-click or . You can also navigate through the list using arrow up/down keys.


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
You can install napari-folder-browser from within napari by clicking menu Plugins > Install/uninstall Plugins... and entering here:

You can install napari-folder-browser via pip:
pip install napari-folder-browser

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-folder-browser"" is free and open source software
Issues
If you encounter any problems, please create a thread on image.sc along with a detailed description and tag @haesleinhuepf."
37,napari-hdf5-labels-io,Napari plugin to store set of layers in a .h5 file. Label layer are stored in a sparse representation,"Description
This IO plugin lets you to store your progress in a single file (.h5 extension). It stores not only the layer's data but also its metadata, meaning that in some way, this IO can be seen as a project file generator.
The current supported layer types are: images, labels and dots.
This plugin was developed to create a connection between napari (for labeling) and YAPiC (a deep learning segmentation tool).
Who is this for?
This plugin is meant to be used for any napari user wanting to store their progress in a single file and for those which use napari as a labeling tool.
It supports any data dimensionality and it was designed to improve the memory efficiency when storing label layers.
Additionally, YAPiC supports the files generated by this IO to perform image segmentation.
Quick start
Saving .h5 files
With napari-hdf5-labels-io installed, use napari as alway. once you are done, click in File, click in Save Selected Layer(s)... (Ctrl+S) or Save All Layers... (Ctrl+Shift+S) and write the output file name as filename.h5. Including the "".h5"" extension at the end of the name will automatically activate the plugin.
Opening .h5 files
To open a .h5 file written with this plugin, you can open this file as any other (either by the Open File option in the File menu or dragging it to the main window)."
38,napari-imagecodecs,A napari plugin for reading files via imagecodecs,
39,napari-imc,Imaging Mass Cytometry (IMC) file type support for napari,"Supported file formats:
 - Fluidigm® MCD™
 - Fluidigm® TXT
Supported image types:
  - Panoramas (single-channel, color)
  - Acquisitions (multi-channel, grayscale)
All images are loaded co-registered within the machine's coordinate system."
40,napari-itk-io,File IO with itk for napari,"napari-itk-io





File IO with itk for napari.
Supported image file formats:

BioRad
BMP
DICOM
DICOM Series
ITK HDF5
JPEG
GE4,GE5,GEAdw
Gipl (Guys Image Processing Lab)
LSM
MetaImage
MINC 2.0
MGH
MRC
NifTi
NRRD
Portable Network Graphics (PNG)
Tagged Image File Format (TIFF)
VTK legacy file format for images

For DICOM Series, select the folder containing the series with File -> Open
Folder.... The first series will be selected and sorted spatially.
Installation
You can install napari-itk-io via pip:
pip install napari-itk-io

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
Follow the itk contributing
guidelines
and the itk code of
conduct.
License
Distributed under the terms of the Apache Software License 2.0 license,
""napari-itk-io"" is free and open source software.
Issues
If you encounter any problems, please file an issue along with a detailed description."
41,napari-lazy-openslide,A plugin to lazily load multiscale whole-slide images with openslide and dask.,"napari-lazy-openslide




An experimental plugin to lazily load multiscale whole-slide tiff images with openslide and dask.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
Step 1.) Make sure you have OpenSlide installed. Download instructions here.

NOTE: Installation on macOS is easiest via Homebrew: brew install openslide. Up-to-date and multiplatform 
binaries for openslide are also avaiable via conda: conda install -c sdvillal openslide-python

Step 2.) Install napari-lazy-openslide via pip:
pip install napari-lazy-openslide

Usage
This plugin tries to be conservative with what files it will attempt to provide a reader.
It will only attempt to read .tif and .tiff files that openslide will open and are 
detected as multiscale (openslide.OpenSlide.level_count > 1). Under the hood, 
napari-lazy-openslide wraps the openslide reader with a valid zarr.Store where each 
each pyramidal level is exposed as a separate zarr.Array with shape (y,x,4).
The plugin is experimental and has only been tested with CAMELYON16 and CAMELYON17 datasets, 
which can be downloaded here.
bash
$ napari tumor_004.tif

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-lazy-openslide"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
42,napari-lfdfiles,A napari plugin for reading files via lfdfiles,
43,napari-live-recording,A napari plugin for live video recording with a generic camera device.,The developer has not yet provided a napari-hub specific description.
44,napari-manual-split-and-merge-labels,Split and merge labels in napari manually,"napari-manual-split-and-merge-labels





Split and merge labels in napari manually


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
You can install napari-manual-split-and-merge-labels via pip:
pip install napari-manual-split-and-merge-labels

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-manual-split-and-merge-labels"" is free and open source software
Issues
If you encounter any problems, please create a thread on image.sc along with a detailed description and tag @haesleinhuepf."
45,napari-mat-images,A plugin to load images stored in MATLAB .mat files with napari,"napari-mat-images



Features
This plugin loads image variables stored in MATLAB .mat files into napari.
It loads any variable that looks like an image.
Presently, that includes any array with more than two dimensions with size greater than 20 pixels (determined by shape_is_image()).
If loading a variable with 3 or more dimensions, the plugin assumes that it is a stack of images, and the dimension with greatest size is the axis of the stack.
Loading Large Files
If loading a large .mat file saved in HDF5/v7.3 format, chunks of the images are loaded as needed, resulting in fast initial load, but potentially slower scrolling.
Slices of the image stacks are randomly sampled to determine min/max contrast values.
Requirements
This plugin relies on scipy to load small .mat files and h5py (with dask) to load larger HDF5/v7.3 .mat files.
It implicitly requires napari for use.
Installation
napari-mat-images requires napari to be installed, although it is not listed as a requirement for installation.
This plugin relies on plugin functionality found in napari version > 0.2.12. This can be installed via pip from PyPI:
$ pip install napari>0.2.12

You can install napari-mat-images via pip from PyPI:
$ pip install napari-mat-images

Usage
Once installed, the plugin will be used whenever trying to load a .mat file.
This can be done from the napari GUI or commandline:
$ napari my_file.mat

Contributing
Contributions are very welcome.
Tests can be run with pytest,
please ensure the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license, napari-mat-images is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description.

This napari plugin was generated with Cookiecutter along with napari\'s cookiecutter-napari-plugin template."
46,napari-medical-image-formats,A Plugin in order to read medical image formats such as DICOM and NIfTI,"napari-medical-image-formats



A Plugin in order to read medical image formats such as DICOM and NIfTI without any meta informations. This will be updated soon.

Installation
You can install napari-medical-image-formats via pip:
pip install napari-medical-image-formats

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-medical-image-formats"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
47,napari-micromanager,GUI interface between napari and micromanager,"napari-micromanager





GUI interface between napari and micromanager
🚧 Experimental!  Work in progress!  Here be 🐲 🚧

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-micromanager via pip:
pip install napari-micromanager

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
Launching napari with plugin
You can launch napari and automatically load this plugin using the launch-dev.py script:
bash
python launch-dev.py
Alternatively you can run:
bash
napari -w micromanager
License
Distributed under the terms of the BSD-3 license,
""napari-micromanager"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
48,napari-mrcfile-handler,"A simple plugin to read, write and adjust mrcfiles in napari.",The developer has not yet provided a napari-hub specific description.
49,napari-mrcfile-reader,read MRC format image files into napari,"napari-mrcfile-reader





Read MRC format image files into napari using the mrcfile package from CCP-EM


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
You can install napari-mrcfile-reader via pip:
pip install napari-mrcfile-reader

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-mrcfile-reader"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
50,napari-mri,A simple plugin to use with napari for 3D-viewing of                  Magnetic Resonance Imaging file formats,"napari-mri





A simple plugin to use with napari for 3D-viewing of Magnetic Resonance Imaging file formats

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-mri via pip:
pip install napari-mri

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-mri"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
51,napari-ndtiffs,napari plugin for nd tiff folders with OpenCl deskew,"napari-ndtiffs





napari plugin for nd tiff folders with optional OpenCl-based deskewing.
Built-in support for folders of (skewed) lattice light sheet tiffs.


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Features

Drag and drop a folder of tiffs onto napari window to view easily 
(currently designed to detect  lattice light sheet tiffs, but easily
    adjustable)
If lattice Settings.txt file is found, will deskew automatically (only if
  necessary)
Lazily loads dataset on demand.  quickly load preview your data.
Handles .zip archives as well!  Just directly compress your tiff folder,
  then drop it into napari.
All-openCL deskewing, works on GPU as well as CPU, falls back to scipy if
  pyopencl is unavailable.

It would not be hard to support arbitrary filenaming patterns!  If you have a
folder of tiffs with a consistent naming scheme and would like to take advantage
of this plugin, feel free to open an issue!
Installation
You can install napari-ndtiffs via pip:
shell
pip install napari-ndtiffs
To also install PyOpenCL (for faster deskewing):
shell
pip install napari-ndtiffs[opencl]
Usage
In most cases, just drop your folder onto napari, or use viewer.open(""path"")
Overriding parameters
You can control things like voxel size and deskewing angle as follows:
```python
from napari_ndtiffs import parameter_override
import napari
viewer = napari.Viewer()
with parameter_override(angle=45, name=""my image""):
    viewer.open(""path/to/folder"", plugin=""ndtiffs"")
```
Valid keys for parameter_override include:

dx: (float) the pixel size, in microns
dz: (float)the z step size, in microns
deskew: (bool) whether or not to deskew, (by default, will deskew if angle > 0, or if a lattice metadata file is detected that requires deskewing) 
angle: (float) the angle of the light sheet relative to the coverslip
padval: (float) the value with which to pad the image edges when deskewing (default is 0)
contrast_limits: (2-tuple of int) (min, max) contrast_limits to use when viewing the image
name: (str) an optional name for the image

Sample data
Try it out with test data: download sample data
You can unzip if you like, or just drag the zip file onto the napari window.
Or, from command line, use:
bash
napari path/to/lls_mitosis.zip
Debugging
To monitor file io and deskew activity, enter the following in the napari console:
python
import logging
logging.getLogger('napari_llsfolder').setLevel('DEBUG')
Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-ndtiffs"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
52,napari-netpbmfile,A napari plugin for reading files via netpbmfile,
53,napari-nikon-nd2,Opens Nikon ND2 files into napari.,"napari-nikon-nd2





Opens Nikon ND2 files into napari. This plugin uses the nd2reader and pims python packages. 

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-nikon-nd2 via pip:
pip install napari-nikon-nd2

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the Apache Software License 2.0 license,
""napari-nikon-nd2"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description.
Credits
This napari plugin was created using Napari Delta Vision Reader and
the Allen Institute IO plugin as examples."
54,napari-nucleaizer,Napari integration of the nucleaizer algorithm. (https://nucleaizer.org),"napari-nucleaizer





GUI for the nucleaAIzer method in Napari.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation

Create & enable a virtual env.
Instal napari.
Install nucleaizer_backend.
Install this project into the same virtual environment.

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-nucleaizer"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
55,napari-oiffile,A napari plugin for reading files via oiffile,
56,napari-ome-zarr,A reader for zarr backed OME-NGFF images.,"Description
This plugin provides a reader for zarr backed OME-NGFF images in napari. The reader
will inspect the .zattrs metadata provided and pass any relevant metadata, including channel, scale and colormap metadata. 

The example above uses the image at https://idr.openmicroscopy.org/webclient/?show=image-6001240
Supported Data
This plugin is designed to allow bioimaging researchers and analysts to explore their
multi-resolution images stored in Zarr filesets (according to the OME zarr spec)
without needing an intricate understanding of zarr, or the spec itself.
This plugin supports reading all images recognised as ome-zarr, namely, containing
well-formed .zattrs and .zgroup files, as well as the appropriate directory 
hierarchy as described in the spec. 
The image metadata from OMERO will be used to set channel names, colormaps and rendering settings in napari.
Quickstart
You can open local or remote images using napari at the terminal and the path to your file:
```
$ napari 'https://s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001240.zarr/'
also works with local files
$ napari 6001240.zarr
```
OR in python:
```python
import napari
viewer = napari.Viewer()
viewer.open('https://s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001240.zarr/')
napari.run()
```
If a single zarray is passed to the plugin, it will be opened without the use of
the metadata:
$ napari '/tmp/6001240.zarr/0'
If an image group contains labels, they will also be opened, and added as a 
separate layer in napari.
When the labels group metadata additionally contains ""rgba"" and ""properties"" keys, 
the labels will be given appropriate colors and the properties will be displayed 
in the status bar.
Working with ome-zarr images can be more convenient using the command-line interface
and utility functions of our associated library ome-zarr. For more information 
please see the package documentation for ome-zarr.
Getting Help
If you discover a bug with the plugin, or would like to request a new feature, please
raise an issue on our repository at https://github.com/ome/napari-ome-zarr.
If you would like assistance with using the plugin, or converting images to
ome-zarr format, please reach out on image.sc.
How to Cite
To cite OME-NGFF:
Next-generation file format (NGFF) specifications for storing bioimaging data in the cloud. J. Moore, et al. Editors. Open Microscopy Environment Consortium, 20 November 2020. This edition of the specification is https://ngff.openmicroscopy.org/0.1/. The latest edition is available at https://ngff.openmicroscopy.org/latest/. (doi:10.5281/zenodo.4282107)
To cite this plugin:
ome-zarr-py: Experimental implementation of next-generation file format (NGFF) specifications for storing bioimaging data in the cloud. OME; et al. 06 October 2020. URL: https://doi.org/10.5281/zenodo.4113931"
57,napari-omero,napari/OMERO interoperability,"napari-omero





This package provides interoperability between the
OMERO image management platform, and
napari: a fast, multi-dimensional image
viewer for python.
It provides a GUI interface for browsing an OMERO instance from within napari,
as well as command line interface extensions for both OMERO and napari CLIs.

Features

GUI interface to browse remote OMERO data, with thumbnail previews.
Loads remote nD images from an OMERO server into napari
Planes are loading on demand as sliders are moved (""lazy loading"").
session management (login memory)
OMERO rendering settings (contrast limits, colormaps, active channels, current
  Z/T position) are applied in napari

as a napari dock widget
To launch napari with the OMERO browser added, install this
package and run:
bash
napari_omero
The OMERO browser widget can also be manually added to the napari viewer:
```python
import napari
from napari_omero import OMEROWidget
with napari.gui_qt():
    viewer = napari.Viewer()
    viewer.window.add_dock_widget(OMEROWidget(), area=""right"")
```
as a napari plugin
This package provides a napari reader plugin that accepts OMERO resources as
""proxy strings"" (e.g. Image:<ID>) or as OMERO webclient
URLS.
```python
viewer = napari.Viewer()
omero object identifier string
viewer.open(""Image:1"", plugin=""omero"")
or URLS: https://help.openmicroscopy.org/urls-to-data.html
viewer.open(""http://yourdomain.example.org/omero/webclient/?show=image-314"")
```
these will also work on the napari command line interface, e.g.:
```bash
napari Image:1
or
napari http://yourdomain.example.org/omero/webclient/?show=image-314
```
as an OMERO CLI plugin
This package also serves as a plugin to the OMERO CLI
bash
omero napari view Image:1

ROIs created in napari can be saved back to OMERO via a ""Save ROIs"" button.
napari viewer console has BlitzGateway 'conn' and 'omero_image' in context.

installation
Requires python 3.7 - 3.9.
It's easiest to install omero-py from conda, so the recommended install
procedure is to first create a new conda environment (here called ""omero"")
with omero-py installed from the ome channel, and then use pip to
install napari-omero (until we have a conda package available).
sh
conda create -n omero -c ome python=3.7 omero-py
conda activate omero
pip install napari-omero
issues
| ❗  | This is alpha software & some things will be broken or sub-optimal!  |
| --- | -------------------------------------------------------------------- |

experimental & definitely still buggy!  Bug
  reports are welcome!
remote loading can be very slow still... though this is not strictly an issue
  of this plugin.  Datasets are wrapped as delayed dask stacks, and remote data
  fetching time can be significant.  Plans for asynchronous
  rendering in napari and
  tiled loading from OMERO
  may eventually improve the subjective performance... but remote data loading
  will likely always be a limitation here.

contributing
Contributions are welcome!  To get setup with a development environment:
```bash
clone this repo:
git clone https://github.com/tlambert03/napari-omero.git
change into the new directory
cd napari-omero
create conda environment
conda env create -f environment.yml
activate the new env
conda activate napari-omero
```
To maintain good code quality, this repo uses
flake8,
mypy, and
black.  To enforce code quality when you commit
code, you can install pre-commit
```bash
install pre-commit which will run code checks prior to commits
pre-commit install
```
The original OMERO data loader and CLI extension was created by Will
Moore.
The napari reader plugin and GUI browser was created by Talley
Lambert"
58,napari-plot-profile,Plot intensity along a line in napari,"napari-plot-profile





Plot intensities along a line in napari.

Usage


Open some images in napari.


Add a shapes layer.




Activate the line drawing tool or the path tool and draw a line.



After drawing a line, click on the menu Plugins > Measurements (Plot Profile)
If you modify the line, you may want to click the ""Refresh"" button to redraw the profile.


To see how these steps can be done programmatically from python, check out the demo notebook

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
You can install napari-plot-profile via pip:
pip install napari-plot-profile

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-plot-profile"" is free and open source software
Issues
If you encounter any problems, please create a thread on image.sc along with a detailed description and tag @haesleinhuepf."
59,napari-plugin-search,Find napari plugins,"napari-plugin-search





Find napari plugins

Usage
Enter the name of the plugin you are searching for and use the up and down arrow keys to navigate between them. 
Hit Enter to start a plugin.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
You can install napari-plugin-search via pip:
pip install napari-plugin-search

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-plugin-search"" is free and open source software
Issues
If you encounter any problems, please create a thread on image.sc along with a detailed description and tag @haesleinhuepf."
60,napari-properties-plotter,A napari plugin that automatically generates interactive plots based on layer properties.,"napari-properties-plotter





A napari plugin that automatically generates interactive plots based on layer properties.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-properties-plotter via pip:
pip install napari-properties-plotter

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-properties-plotter"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
61,napari-properties-viewer,A viewer for napari layer properties,"napari-properties-viewer





A viewer for napari layer properties

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-properties-viewer via pip:
pip install napari-properties-viewer

Using the properties viewer table

Open a a napari viewer with a layer with properties (e.g., Points)
View the properties by opening the properties viewer plugin from Plugins menu -> Add dock widget -> napari-propertiews-viewer: properties table
The layer property values are now displayed in the table widget. You can edit the values by double clicking the cell of interest and entering a new value.

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-properties-viewer"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
62,napari-pyclesperanto-assistant,GPU-accelerated image processing in napari using OpenCL,"napari-pyclesperanto-assistant







The py-clEsperanto-assistant is a yet experimental napari plugin for building GPU-accelerated image processing workflows. 
It is part of the clEsperanto project and thus, aims at removing programming language related barriers between image processing ecosystems in the life sciences. 
It uses pyclesperanto and with that pyopencl as backend for processing images.
This plugin was generated with Cookiecutter using with napari's cookiecutter-napari-plugin template.

Installation
It is recommended to install the assistant via conda:
shell
conda create --name bio11 python==3.8.5 
conda activate bio11 
conda install -c conda-forge pyopencl==2021.2.1
pip install napari-pyclesperanto-assistant
pip install napari[all]
Alternatively, you can install the assistant using napari's plugin installer in the menu Plugins > Install/uninstall Packages.
Windows users should paste this URL
https://github.com/clEsperanto/napari_pyclesperanto_assistant/blob/master/installation_help/pyopencl-2020.3.1+cl12-cp38-cp38-win_amd64.whl?raw=true
in this field and click on Install before proceeding:

Afterwards, click install clEsperanto like by clicking on Install here:

You can then start napari, e.g. from command line, and find the assistant in the Plugins menu.
shell
napari

Features
pyclesperanto offers various possibilities for processing images. It comes from developers who work in life sciences and thus, it may be focused towards processing two- and three-dimensional microscopy image data showing cells and tissues. A selection of pyclesperanto's functionality is available via the assistant user interface. Typical workflows which can be built with this assistant include
* image filtering
  * denoising / noise reduction (mean, median, Gaussian blur)
  * background subtraction for uneven illumination or out-of-focus light (bottom-hat, top-hat, subtract Gaussian background)
  * grey value morphology (local minimum, maximum. variance)
  * gamma correction
  * Laplace operator
  * Sobel operator
* combining images
  * masking
  * image math (adding, subtracting, multiplying, dividing images) 
  * absolute / squared difference
* image transformations
  * translation
  * rotation
  * scale
  * reduce stack
  * sub-stacks
* image projections
  * minimum / mean / maximum / sum / standard deviation projections
* image segmentation
  * binarization (thresholding, local maxima detection)
  * labeling
  * regionalization
  * instance segmentation
  * semantic segmentation
  * detect label edges
  * label spots
  * connected component labeling
  * Voronoi-Otsu-labeling
* post-processing of binary images
  * dilation
  * erosion
  * binary opening
  * binary closing 
  * binary and / or / xor
* post-processing of label images
  * dilation (expansion) of labels
  * extend labels via Voronoi
  * exclude labels on edges
  * exclude labels within / out of size / value range
  * merge touching labels
* parametric maps
  * proximal / touching neighbor count
  * distance measurements to touching / proximal / n-nearest neighbors
  * pixel count map
  * mean / maximum / extension ratio map
* label measurements / post processing of parametric maps
  * minimum / mean / maximum / standard deviation intensity maps
  * minimum / mean / maximum / standard deviation of touching / n-nearest / neighbors
* neighbor meshes
  * touching neighbors
  * n-nearest neighbors
  * proximal neighbors
  * distance meshes
* measurements based on label images
  * bounding box 2D / 3D
  * minimum / mean / maximum / sum / standard deviation intensity
  * center of mass
  * centroid
  * mean / maximum distance to centroid (and extension ratio shape descriptor)
  * mean / maximum distance to center of mass (and extension ratio shape descriptor)
* code export
  * python / Fiji-compatible jython
  * python jupyter notebooks
* pyclesperanto scripting
  * cell segmentation
  * cell counting
  * cell differentiation
  * tissue classification
Usage
Start up the assistant
Start up napari, e.g. from the command line:
napari
Load example data, e.g. from the menu File > Open Samples > clEsperanto > CalibZAPWfixed and 
start the assistant from the menu Plugins > clEsperanto > Assistant. Select a GPU in case you are asked to.

In case of two dimensional timelapse data, an initial conversion step might be necessary depending on your data source. 
Click the menu Plugins > clEsperanto > Convert to 2d timelapse. In the dialog, select the dataset and click ok. 
You can delete the original dataset afterwards:

Set up a workflow
Choose categories of operations in the top right panel, for example start with denoising using a Gaussian Blur with sigma 1 in x and y.

Continue with background removal using the top-hat filter with radius 5 in x and y.

For labeling the objects, use Voronoi-Otsu-Labeling with both sigma parameters set to 2.

The labeled objects can be extended using a Voronoi diagram to derive a estimations of cell boundaries.

You can then configure napari to show the label boundaries on top of the original image:

When your workflow is set up, click the play button below your dataset:

Code generation
You can also export your workflow as Python/Jython code or as notebook.

After exporting your workflow as Jupyter notebook, you can start the notebook from the command line using
jupyter notebook my_notebook.ipynb
In some cases you need to replace the command cle.imread('None)` with a command loading your image data. 
After that, you can execute the notebook.

You can also export code to the clipboard or as python code to disc. 
This python code can also be executed in Fiji`s Jython, in case the CLIJx-assistant is installed.

Also note: The generated python/jython code is not capable of processing timelapse data,
you need to program a for-loop processing timepoints individually yourself. 
Work in progress, contributions welcome.
For developers
Getting the recent code from github and locally installing it
```
git clone https://github.com/clesperanto/napari_pyclesperanto_assistant.git
pip install -e ./napari_pyclesperanto_assistant
```
Optional: Also install pyclesperantos recent source code from github:
```
git clone https://github.com/clEsperanto/pyclesperanto_prototype.git
pip install -e ./pyclesperanto_prototype
```
Feedback welcome!
clEsperanto is developed in the open because we believe in the open source community. See our community guidelines. Feel free to drop feedback as github issue or via image.sc
Imprint"
63,napari-sdeconv,2D and 3D image deconvolution,"Description
napari-sdeconv is a suite of Napari plugins for the sdeconv library
<https://sylvainprigent.github.io/sdeconv/>_ dedicated to 2D and 3D images deconvolution. It contains multiple
deconvolution algorithms and PSF Generators.

Example of deconvolution with Spitfire



Example of how to generate a 3D PSF


Installation
You can install napari-sdeconv via pip:
pip install napari-sdeconv

Note that the current version of the package on support python 3.9    
The deconvolution depends on FFTW c++ library. FFTW must be installed for the 
deconvolution plugin to work. The easiest method to install FFTW is to use 
conda:
conda install -c conda-forge fftw

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the GNU GPL v3.0 license,
""napari-tracks-reader"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
64,napari-sdtfile,A napari plugin for reading files via sdtfile,
65,napari-segment-blobs-and-things-with-membranes,A plugin based on scikit-image for segmenting nuclei and cells based on fluorescent microscopy images with high intensity in nuclei and/or membranes,"napari-segment-blobs-and-things-with-membranes





A plugin based on scikit-image for segmenting nuclei and cells based on fluorescent microscopy images with high intensity in nuclei and/or membranes. 
The available functions and their user interface based on magicgui are shown below. You can also call these functions
as shown in the demo notebook.
Voronoi-Otsu-Labeling
This algorithm uses Otsu's thresholding method in combination with 
Gaussian blur and a 
Voronoi-Tesselation 
approach to label bright objects such as nuclei in an intensity image. The alogrithm has two sigma parameters which allow
you to fine-tune where objects should be cut (spot_sigma) and how smooth outlines should be (outline_sigma).
This implementation aims to be similar to Voronoi-Otsu-Labeling in clesperanto.

Seeded Watershed
Starting from an image showing high-intensity membranes and a seed-image where objects have been labeled (e.g. using Voronoi-Otsu-Labeling),
objects are labeled that are constrained by the membranes.

Gaussian blur
Applies a Gaussian blur to an
image. This might be useful for denoising, e.g. before applying the Threshold-Otsu method.

Subtract background
Subtracts background using scikit-image's rolling-ball algorithm. 
This might be useful, for example to make intensity of membranes more similar in different regions of an image.

Threshold Otsu
Binarizes an image using scikit-image's threshold Otsu algorithm, also known as 
Otsu's method.

Split touching objects (formerly known as binary watershed).
In case objects stick together after thresholding, this tool might help.
It aims to deliver similar results as ImageJ's watershed implementation.

Connected component labeling
Takes a binary image and produces a label image with all separated objects labeled differently. Under the hood, it uses
scikit-image's label function.


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
Download, unzip and install napari from its github releases page:

Afterwards, go to the menu Plugins > Install/uninstall plugins... and click on the install button next to napari-segment-blobs-and-things-with-membranes:

You can also install napari-segment-blobs-and-things-with-membranes via pip:
pip install napari-segment-blobs-and-things-with-membranes

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-segment-blobs-and-things-with-membranes"" is free and open source software
Issues
If you encounter any problems, please create a thread on image.sc along with a detailed description and tag @haesleinhuepf."
66,napari-skimage-regionprops,A regionprops table widget plugin for napari,"napari-skimage-regionprops





A napari plugin for measuring properties of labeled objects based on scikit-image

Features
The user can select categories of features for feature extraction in the user interface. These categories contain measurements from the scikit-image regionprops list of measurements library:


size:


area


bbox_area


convex_area


equivalent_diameter


intensity:


max_intensity 


mean_intensity


min_intensity


standard_deviation_intensity (extra_properties implementation using numpy)


perimeter:


perimeter


perimeter_crofton


shape


major_axis_length


minor_axis_length


orientation


solidity


eccentricity


extent


feret_diameter_max


local_centroid


position:


centroid


bbox


weighted_centroid


moments:


moments


moments_central


moments_hu


moments_normalized


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
You can install napari-skimage-regionprops via pip:
pip install napari-skimage-regionprops

Or if you plan to develop it:
git clone https://github.com/haesleinhuepf/napari-skimage-regionprops

cd napari-skimage-regionprops

pip install -e .

If there is an error message suggesting that git is not installed, run conda install git.
Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-skimage-regionprops"" is free and open source software
Issues
If you encounter any problems, please create a thread on image.sc along with a detailed description and tag @haesleinhuepf."
67,napari-spacetx-explorer,visualizer for spatial omic data,The developer has not yet provided a napari-hub specific description.
68,napari-stl-exporter,Exports label images to 3D-printable stl files.,"napari-stl-exporter





Exports label images to 3D-printable stl files. 
Features
You can easily create label layers from normal image layers in napari by converting them:

The label layer is then saved as a 3D-printable stl file if the filename is provided accordingly (e.g., MyExampleFile.stl). To actually send your object to a 3D-printer, it has to be further converted with a Slicer program which actually controls the print parameters (Level of detail, layer thickness, etc). Popular freeware slicers are:

Slic3r
Prusa Slicer


This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-stl-exporter via pip:
pip install napari-stl-exporter

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-stl-exporter"" is free and open source software
Issues
If you encounter any problems, please [file an issue] along with a detailed description or post to image.sc and tag El_Pollo_Diablo"
69,napari-stracking,Linking and tracks analysis,"Description
The STracking suite provides a set of plugins for particles tracking in 2D+t and 3D+t images. 
A classical particles tracking pipeline is made of 5 sequential steps:

Particles detection frame by frame



Particles properties calculation (optional)



Particles linking



Tracks features extraction (optional)



Tracks filtering (optional)


Installation
You can install napari-stracking via pip:
pip install napari-stracking

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the GNU GPL v3.0 license,
""napari-tracks-reader"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
70,napari-svg,A plugin for reading and writing svg files with napari,"napari-svg





A plugin for reading and writing svg files with napari

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install napari-svg via pip:
pip install napari-svg

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-svg"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
71,napari-tifffile,A napari plugin for reading files via tifffile,
72,napari-tissuumaps,A plugin to add compatibility with Tissuumaps,The developer has not yet provided a napari-hub specific description.
73,napari-tracks-reader,"Read tracks from txt (xml, csv) files to napari","Description
This plugin allows to open particle tracking results from multiple formats into the Napari 
Tracks Layer.
Supported formats
The formats currently supported by this plugin are:
CSV
The most basic format to store particle tracking tracks is a CSV file containing the tracks table.
In this format each line is a particle and each column a property of the particle. The table
headers must be TrackID, t, x, y, z. Note that the header order does not matter:
| TrackID       | t | x | y | z |
| :------------ | :----------: | :----------: | :----------: | -----------: |
| 0 | 16   | 41.5828343348868  | 47.505930020081664| 0 |
| 0 | 17   | 41.48425270538317 | 51.6023835597057 | 0 |
The raw CSV file is a classical comma-separated values format: 
csv
TrackID,t,x,y,z
0,16, 41.5828343348868, 47.505930020081664, 0
0,17, 41.48425270538317, 51.6023835597057, 0
...
[!NOTE]
This CSV format does not support split and merge events
TrackMate
The TrackMate format is the XML model file générated by the TrackMate Fiji 
plugin. 
The XML file from TrackMate should not be manually modified and and contains a Model element:
```xml


...





...
```
All the particles features from the TrackMate model file are loaded in the napari tracks properties. 
[!NOTE]
This format supports split and merge events
Icy
The Icy format is a XML file generated by the Icy software.
The XML file from ICY should not be manually modified and starts with the root element:
```xml







      ...
```
[!TIP]
This format supports split and merge events
ISBI
The ISBI format is a XML format used for the ISBI tracking challenge. This format must contain 
a root element and a list of particles in a TrackContestISBI2012 element:
```xml







``` 
[!NOTE]
This format does not support split and merge events
Quickstart
You can open local tracks using napari at the terminal and the path to your file:
$ napari /path/to/your/tracks.xml
OR in python:
```python
import napari
viewer = napari.Viewer()
viewer.open('/path/to/your/tracks.xml')
napari.run()
```
Getting Help
If you discover a bug with the plugin, or would like to request a new feature, please
raise an issue on our repository at https://github.com/sylvainprigent/napari-tracks-reader."
74,napari-webcam,Use your webcam from napari,"napari-webcam





Use your webcam from within napari!

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.
Installation
You can install napari-webcam via pip:
pip install napari-webcam

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""napari-webcam"" is free and open source software
Issues
If you encounter any problems, please open a thread on image.sc along with a detailed description."
75,napari-yapic-prediction,Napari widget plugin to perform yapic model segmentation prediction in the napari window,"napari-yapic-prediction





napari widget plugin to perform YAPiC model segmentation prediction in the napari window.

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Description
This napari plugin provides a widget to upload a YAPiC trained model and perform segmentation over all the present images in the napari window. The segmentation results are uploaded as napari layers into the viewer automatically with the name structure of imgename_prediction.
Installation


Please install either GPU or CPU version of tensorflow before installing the plugin depending on your system.
One of the plugin dependency is yapic that currently has sensitivity to tensorflow versions.
This behaviour will be removed in future.


You can install napari-yapic-prediction via pip:
pip install napari-yapic-prediction


Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the GNU GPL v3.0 license,
""napari-yapic-prediction"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
76,napari_video,napari plugin for reading videos.,"napari-video
Napari plugin for working with videos.
Relies on pyvideoreader as a backend which itself uses opencv for reading videos.
Installation
shell
pip install napari[all] napari_video
Usage
From a terminal:
shell
napari video.avi
Or from within python:
```shell
import napari
from napari_video.napari_video import VideoReaderNP
path='video.mp4'
vr = VideoReaderNP(path)
with napari.gui_qt():
    viewer = napari.view_image(vr, name=path)
```
Internals
napari_video.napari_video.VideoReaderNP exposes a video with a numpy-like interface, using opencv as a backend.
For instance, open a video:
python
vr = VideoReaderNP('video.avi')
print(vr)
video.avi with 60932 frames of size (920, 912, 3) at 100.00 fps
Then

vr[100] will return the 100th frame as a numpy array with shape (902, 912, 3).
vr[100:200:10] will return 10 frames evenly spaced between frame number 100 and 200 (shape (10, 902, 912, 3)).
Note that by default, single-frame and slice indexing return 3D and 4D arrays, respectively. To consistently return 4D arrays, open the video with remove_leading_singleton=False. vr[100] will then return a (1, 902, 912, 3) array.
We can also request specific ROIs and channels. For instance, vr[100:200:10,100:400,800:850,1] will return an array with shape (10, 300, 50, 1).
"
77,nd2-dask,Plugin to load nd2 data into napari,"nd2-dask





Plugin to load nd2 data into napari

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install nd2-dask via pip:
pip install nd2-dask

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""nd2-dask"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
78,platelet-unet-watershed,Segment platelets with pretrained unet and affinity watershed,"platelet-unet-watershed





Segment platelets with pretrained unet and affinity watershed

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install platelet-unet-watershed via pip:
pip install platelet-unet-watershed

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""platelet-unet-watershed"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
79,stardist-napari,Object Detection with Star-convex Shapes,"StarDist Napari Plugin


This project provides the napari plugin for StarDist, a deep learning based 2D and 3D object detection method with star-convex shapes. StarDist has originally been developed (see papers) for the segmentation of densely packed cell nuclei in challenging images with low signal-to-noise ratios. The plugin allows to apply pretrained and custom trained models from within napari.

Installation & Usage
Install the plugin with pip install stardist-napari or from within napari via Plugins > Install/Uninstall Package(s)…. If you want GPU-accelerated prediction, please read the more detailed installation instructions for StarDist.
You can activate the plugin in napari via Plugins > StarDist: StarDist. Example images for testing are provided via File > Open Sample > StarDist.
For a more detailed demonstration of the plugin, please watch this short video.
There's no dedicated documentation yet, but the most important parameters are identical to those of our StarDist ImageJ/Fiji plugin, which are documented here.
If you use this plugin for your research, please cite us.
Troubleshooting & Support

The image.sc forum is the best place to start getting help and support. Make sure to use the tag stardist, since we are monitoring all questions with this tag.
For general questions about StarDist, it's worth taking a look at the frequently asked questions (FAQ).
If you have technical questions or found a bug, feel free to open an issue.
"
80,waver,Wave simulations,"waver





Run simulations of the wave equation in nD on grids of variable speed in Python. This library owes a lot of its design and approach to the fdtd library, a Python 3D electromagnetic FDTD simulator.
This package allows for a fair amount of customization over your wave simulation. You can
 - specify the size and spacing of the grid
 - specify the time step for the simulation, which will be checked to ensure stability of the simulation
 - specify the duration of the simulation
 - setting a variable speed array (one value per grid point) to allow for ""objects"" in your environment
 - set the source of the wave, which can be a point, line, or any (n-1)D subarray
 - record the wave with a detector, which can be the full grid, the full boundary, or a particular boundary
 - use convenience methods to run many simulations with different sources on the same grid and detector combination
You can use napari, a multi-dimensional image viewer for Python, to allow for easy visualization of the detected wave. Some functionality is also available as a napari plugin to allow for running simulations from a graphical user interface.
Results can look like
https://user-images.githubusercontent.com/6531703/128283012-a784ec06-4df9-4ddf-bf4f-e21b927fe4a3.mov

Installation
You can install waver via pip:
pip install waver

Usage
Convenience Methods
The most convenient way to use waver is to use one of two convenience methods that will create and run a simulation
for you and return the results.
The first method run_single_source allows you to run a single simulation with a single source on one grid and 
record the results using a detector. For example
```python
from waver.simulation import run_single_source
single_sim_params = {
    'size': (12.8e-3, 12.8e-3),
    'spacing': 100e-6,
    'duration': 80e-6,
    'min_speed': 343,
    'max_speed': 686,
    'speed': 686,
    'time_step': 50e-9,
    'temporal_downsample': 2,
    'location': (6.4e-3, 6.4e-3),
    'period': 5e-6,
    'ncycles':1,
}
detected_wave, speed_grid = run_single_source(**single_sim_params)
```
The second method run_multiple_sources allows you to run multiple simulations with multiple sources on the same
grid and with the same detector and return the results. For example
```python
from waver.simulation import run_multiple_sources
multi_sim_params = {
    'size': (12.8e-3, 12.8e-3),
    'spacing': 100e-6,
    'duration': 80e-6,
    'min_speed': 343,
    'max_speed': 686,
    'speed': 686,
    'time_step': 50e-9,
    'temporal_downsample': 2,
    'sources': [{
        'location': (6.4e-3, 6.4e-3),
        'period': 5e-6,
        'ncycles':1,
    }]
}
detected_wave, speed_grid = run_multiple_sources(**multi_sim_params)
```
The main difference between these two methods is that run_multiple_sources takes a sources parameter which takes a list 
of dictionaries with keys corresponding to source related keyword arguments found in run_single_source.
Visualization
If you want to quickly visualize the results of run_multiple_sources, you can use the run_and_visualize command which will 
run the simulation and then launch napari with the results, as seen in examples/2D/point_source.py
```python
from waver.datasets import run_and_visualize
run_and_visualize(**multi_sim_params)
```
Datasets
If you want to run simulations with on many different speed grids you can use the generate_simulation_dataset method as a convenience. The results will be saved to a zarr file of your chosing. You can then use the load_simulation_dataset to load the dataset.
```python
from waver.datasets import generate_simulation_dataset
Define root path for simulation
path = './simulation_dataset.zarr'
runs = 5
Define a simulation, 12.8mm, 100um spacing
dataset_sim_params = {
    'size': (12.8e-3, 12.8e-3),
    'spacing': 100e-6,
    'duration': 80e-6,
    'min_speed': 343,
    'max_speed': 686,
    'speed': 'mixed_random_ifft',
    'time_step': 50e-9,
    'sources': [{
        'location': (None, 0),
        'period': 5e-6,
        'ncycles':1,
    }],
    'temporal_downsample': 2,
    'boundary': 1,
    'edge': 1,
}
Run and save simulation
generate_simulation_dataset(path, runs, **dataset_sim_params)
```
The generate_simulation_dataset allows the speed to be a string that will specify a particular method of randomly generating speed values for the simulation grid.
The Simulation Object
If you'd like to understand in a little bit more detail how a simulation is defined then you might want to use the unerlying simulation object Simulation and manually set key objects like the Source and Detector. A full example of this is as follows
```python
Create a simulation
sim = Simulation(size=size, spacing=spacing, max_speed=max_speed, time_step=time_step)
Set speed array
sim.set_speed(speed=speed, min_speed=min_speed, max_speed=max_speed)
Add source
sim.add_source(location=location, period=period, ncycles=ncycles, phase=phase)
Add detector grid
sim.add_detector(spatial_downsample=spatial_downsample,
                    boundary=boundary, edge=edge)
Run simulation
sim.run(duration=duration, temporal_downsample=temporal_downsample, progress=progress, leave=leave)
Print simulation wave and speed data
print('wave: ', sim.detected_wave)
print('speed: ', sim.grid_speed)
```
Note these steps are done inside the run_single_source method for you as a convenience.
Known Limitations
A perfectly matched layer boundary has recently been added, but might not perform well under all conditions. Additional contributions would be welcome here.
Right now the simulations are quite slow. I'd like to add a JAX backend, but 
havn't done so yet. Contributions would be welcome.
Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""waver"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
81,zarpaint,Paint segmentations directly to on-disk/remote zarr arrays,"zarpaint





Paint segmentations directly to on-disk/remote zarr arrays

This napari plugin was generated with Cookiecutter using with @napari's cookiecutter-napari-plugin template.

Installation
You can install zarpaint via pip:
pip install zarpaint

Contributing
Contributions are very welcome. Tests can be run with tox, please ensure
the coverage at least stays the same before you submit a pull request.
License
Distributed under the terms of the BSD-3 license,
""zarpaint"" is free and open source software
Issues
If you encounter any problems, please file an issue along with a detailed description."
